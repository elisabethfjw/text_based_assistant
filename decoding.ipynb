{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and implement an algorithm to find a translation, given a sentence in the source language. That is, you should try to find\n",
    "\n",
    "E* = argmaxE P(E|F)\n",
    "\n",
    "In plain words, for a given source-language sentence F, we want to find the English-language sentence E that has the highest probability according to the probabilistic model we have discussed. Using machine translation jargon, we call this algorithm the \"decoder.\" In practice, you can't solve this problem exactly and you'll have to come up with some sort of approximation.\n",
    "\n",
    "Exemplify how this algorithm works by showing the result of applying your translation system to a short sentence from the source language.\n",
    "\n",
    "As mentioned, it is expected that you will need to introduce a number of assumptions to make this at all feasible. Please explain all simplifying assumptions that you have made, and the impact you think that they will have on the quality of translations. But why is it an algorithmically difficult problem to find the English sentence that has the highest probability in our model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Sentence: ['jag', 'förklarar']\n",
      "Translated Sentence: ['i', 'explain']\n"
     ]
    }
   ],
   "source": [
    "def greedy_search(source_sentence, translation_probs):\n",
    "    # Initialize an empty list to store the translated words\n",
    "    translated_sentence = []\n",
    "\n",
    "    # Iterate through each word in the source sentence\n",
    "    for source_word in source_sentence:\n",
    "        # Find the English word with the highest probability given the source word\n",
    "        english_word = max(translation_probs[source_word], key=translation_probs[source_word].get)\n",
    "\n",
    "        # Add the selected English word to the translated sentence\n",
    "        translated_sentence.append(english_word)\n",
    "\n",
    "    return translated_sentence\n",
    "\n",
    "# Example usage:\n",
    "# Assuming translation_probs is a dictionary with translation probabilities\n",
    "# where translation_probs[source_word][english_word] represents the probability of translating source_word to english_word\n",
    "translation_probs = {\n",
    "    'jag': {'i': 0.8, 'me': 0.2},\n",
    "    'förklarar': {'explain': 0.9, 'declare': 0.1}\n",
    "    # ... other source-target word pairs\n",
    "}\n",
    "\n",
    "source_sentence = ['jag', 'förklarar']  # Replace with your actual source sentence\n",
    "\n",
    "result = greedy_search(source_sentence, translation_probs)\n",
    "print(\"Source Sentence:\", source_sentence)\n",
    "print(\"Translated Sentence:\", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of a long_sentence is much smaller than that of a short sentence as longer sentences result in more unique combinations of words. The model might not have encountered many of these combinations during training, resulting in a lower probability. Moreover, since the probabilities of each word are multiplied with each other, the longer the sequence, the lower the probability.\n",
    "\n",
    "A possible modification to the code could be building Makemore, which treats each character as a token and predicts the next one. This increases the number of inputs by referencing the inputs it was trained on to allow the model to encounter many combinations to prevent data sparsity.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
